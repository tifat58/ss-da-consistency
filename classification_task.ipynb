{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d6aaf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageFile\n",
    "from random import random\n",
    "from os.path import join, dirname\n",
    "from data.dataset_utils import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import torchvision.models as models\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b69212fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns kaggle\n",
    "def get_kaggle_retinopathy_dataset_info(req_set = 'train'):\n",
    "\n",
    "    # kaggle_csv_file_path = '/mnt/sda/haal02-data/Kaggle-Retinopathy-Datasets/dr-data/trainLabels.csv'\n",
    "    # truncated one\n",
    "    kaggle_csv_file_path = '/mnt/sda/haal02-data/Kaggle-Retinopathy-Datasets/dr-data/truncated_trainLabels.csv'\n",
    "    kaggle_image_path = '/mnt/sda/haal02-data/Kaggle-Retinopathy-Datasets/dr-data/train/'\n",
    "\n",
    "    data_file = pd.read_csv(kaggle_csv_file_path, header=0)\n",
    "    # print(data_file.head())\n",
    "    db_len = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    # 0.7 train, 0.15 val, 0.15 test\n",
    "    if req_set == 'train':\n",
    "        start = 0\n",
    "        # end = 24588\n",
    "        end = int(0.7 * len(data_file))\n",
    "    elif req_set == 'val':\n",
    "        start = int(0.7 * len(data_file))\n",
    "        # end = 29857\n",
    "#         end = int(0.85 * len(data_file))\n",
    "        end = len(data_file) - 1\n",
    "    elif req_set == 'test':\n",
    "        start = int(0.85 * len(data_file))\n",
    "        end = len(data_file) - 1\n",
    "        \n",
    "    elif req_set == 'full':\n",
    "        start = 0\n",
    "        end = len(data_file) - 1\n",
    "\n",
    "    name_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(start, end):\n",
    "        file_name = data_file.iloc[i][0] + '.jpeg'\n",
    "        if os.path.isfile(os.path.join(kaggle_image_path, file_name)):\n",
    "            name_list.append(os.path.join(kaggle_image_path, file_name))\n",
    "            label_list.append(data_file.iloc[i][1])\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    # for idx, row in data_file.iterrows():\n",
    "    #     if os.path.isfile(os.path.join(fgadr_image_path, row[0])):\n",
    "    #         name_list.append(os.path.join(fgadr_image_path, row[0]))\n",
    "    #         label_list.append(row[1])\n",
    "    #     else:\n",
    "    #         print()\n",
    "\n",
    "    return name_list, label_list\n",
    "\n",
    "\n",
    "def get_retinopathy_dataset_info(req_set = 'train'):\n",
    "    fgadr_root_path = '/mnt/sda/haal02-data/FGADR-Seg-Set/Seg-set'\n",
    "    fgadr_csv_file_name = 'DR_Seg_Grading_Label.csv'\n",
    "    fgadr_image_path = '/mnt/sda/haal02-data/FGADR-Seg-Set/Seg-set/Original_Images'\n",
    "\n",
    "    data_file = pd.read_csv(os.path.join(fgadr_root_path, fgadr_csv_file_name), header=None)\n",
    "\n",
    "    db_len = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    # 0.7 train, 0.15 val, 0.15 test\n",
    "    if req_set == 'train':\n",
    "        start = 0\n",
    "        end = 1450\n",
    "    elif req_set == 'val':\n",
    "        start = 1450\n",
    "#         end = 1565\n",
    "        end = len(data_file) - 1\n",
    "    elif req_set == 'test':\n",
    "        start = 1565\n",
    "        end = len(data_file) - 1\n",
    "        \n",
    "    elif req_set == 'full':\n",
    "        start = 0\n",
    "        end = len(data_file) - 1\n",
    "\n",
    "    name_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(start, end):\n",
    "        if os.path.isfile(os.path.join(fgadr_image_path, data_file.iloc[i][0])):\n",
    "            name_list.append(os.path.join(fgadr_image_path, data_file.iloc[i][0]))\n",
    "            label_list.append(data_file.iloc[i][1])\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    # for idx, row in data_file.iterrows():\n",
    "    #     if os.path.isfile(os.path.join(fgadr_image_path, row[0])):\n",
    "    #         name_list.append(os.path.join(fgadr_image_path, row[0]))\n",
    "    #         label_list.append(row[1])\n",
    "    #     else:\n",
    "    #         print()\n",
    "\n",
    "    return name_list, label_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b94e059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "\n",
    "class FGADRDataset(data.Dataset):\n",
    "    def __init__(self, name, split='train', val_size=0, rot_classes=3,\n",
    "            img_transformer=None, bias_whole_image=None, mode='RGB'):\n",
    "        # if split == 'train':\n",
    "        #     names, _, labels, _ = get_split_dataset_info(join(dirname(__file__), 'txt_lists', '%s_train.txt' % name), val_size)\n",
    "        # elif split =='val':\n",
    "        #     _, names, _, labels = get_split_dataset_info(join(dirname(__file__), 'txt_lists', '%s_train.txt' % name), val_size)\n",
    "        # elif split == 'test':\n",
    "        #     names, labels = get_dataset_info(join(dirname(__file__), 'txt_lists', '%s_test.txt' % name))\n",
    "\n",
    "        print(\"Dataset Name: \", name)\n",
    "        if name == 'FGADR':\n",
    "            names, labels = get_retinopathy_dataset_info(req_set=split)\n",
    "        elif name == 'KaggleR':\n",
    "            names, labels = get_kaggle_retinopathy_dataset_info(req_set=split)\n",
    "\n",
    "\n",
    "        # print(names, labels)\n",
    "        # self.data_path = join(dirname(__file__), '..', 'datasets')\n",
    "        self.data_path = '/mnt/sda/haal02-data/FGADR-Seg-Set/Seg-set/Original_Images'\n",
    "        self.names = names\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.rot_classes = rot_classes\n",
    "        self.mode = mode\n",
    "\n",
    "        self.N = len(self.names)\n",
    "        self.bias_whole_image = bias_whole_image\n",
    "        self._image_transformer = img_transformer\n",
    "        \n",
    "        \n",
    "    def get_image(self, index):\n",
    "        # framename = self.data_path + '/' + self.names[index]\n",
    "        framename = self.names[index]\n",
    "        img = Image.open(framename).convert(self.mode)\n",
    "        img = img.resize((512, 512), Image.NEAREST)\n",
    "        return img\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img = self.get_image(index)\n",
    "\n",
    "        img = self._image_transformer(img)\n",
    "        target = self.labels[index]\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "#         sample = {'images': data,\n",
    "#                 'images_ori': self._image_transformer(rot_imgs[0]),\n",
    "#                 'aux_labels': int(order),\n",
    "#                 'class_labels': int(self.labels[index])}\n",
    "#         return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0502bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "learning_rate_decay = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b72024",
   "metadata": {},
   "source": [
    "# FGADR Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9ba3065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  FGADR\n",
      "Dataset Name:  FGADR\n",
      "Dataset Name:  FGADR\n"
     ]
    }
   ],
   "source": [
    "fgadr_norm_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean = [0.4557, 0.2588, 0.1325],\n",
    "                                                        std = [0.2856, 0.1855, 0.1356])\n",
    "                                     ])\n",
    "\n",
    "\n",
    "f_train_set = FGADRDataset(name='FGADR', split='train', img_transformer=fgadr_norm_transform)\n",
    "f_val_set = FGADRDataset(name='FGADR', split='val', img_transformer=fgadr_norm_transform)\n",
    "f_test_set = FGADRDataset(name='FGADR', split='test', img_transformer=fgadr_norm_transform)\n",
    "\n",
    "f_train_loader = torch.utils.data.DataLoader(f_train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "f_val_loader = torch.utils.data.DataLoader(f_val_set, batch_size=batch_size, shuffle=False)\n",
    "f_test_loader = torch.utils.data.DataLoader(f_test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8c654ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  FGADR\n",
      "1841\n"
     ]
    }
   ],
   "source": [
    "basic_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     ])\n",
    "\n",
    "f_full_set = FGADRDataset(name='FGADR', split='full', img_transformer=basic_transform)\n",
    "f_full_loader = torch.utils.data.DataLoader(f_full_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(len(f_full_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c0a7b",
   "metadata": {},
   "source": [
    "# KaggleR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e05bc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  KaggleR\n",
      "Dataset Name:  KaggleR\n",
      "Dataset Name:  KaggleR\n",
      "10721 4594\n"
     ]
    }
   ],
   "source": [
    "#Kaggle set\n",
    "kaggleR_norm_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean = [0.3150, 0.2218, 0.1578],\n",
    "                                                        std = [0.3002, 0.2178, 0.1720])\n",
    "                                     ])\n",
    "k_train_set = FGADRDataset(name='KaggleR', split='train', img_transformer=kaggleR_norm_transform)\n",
    "k_val_set = FGADRDataset(name='KaggleR', split='val', img_transformer=kaggleR_norm_transform)\n",
    "k_test_set = FGADRDataset(name='KaggleR', split='test', img_transformer=kaggleR_norm_transform)\n",
    "\n",
    "k_train_loader = torch.utils.data.DataLoader(k_train_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "k_val_loader = torch.utils.data.DataLoader(k_val_set, batch_size=batch_size, shuffle=False)\n",
    "k_test_loader = torch.utils.data.DataLoader(k_test_set, batch_size=batch_size, shuffle=False)\n",
    "print(len(k_train_set), len(k_val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2bb04f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  KaggleR\n",
      "15315\n"
     ]
    }
   ],
   "source": [
    "basic_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     ])\n",
    "\n",
    "k_full_set = FGADRDataset(name='KaggleR', split='full', img_transformer=basic_transform)\n",
    "k_full_loader = torch.utils.data.DataLoader(k_full_set, batch_size=128, shuffle=False, num_workers=4)\n",
    "print(len(k_full_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43e59ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # computing mean and variance\n",
    "# mean = 0.0\n",
    "# for datas in fgadr_full_loader:\n",
    "#     images, labels = datas\n",
    "# #     images = datas['images']\n",
    "#     batch_samples = images.size(0)\n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "#     mean += images.mean(2).sum(0)\n",
    "    \n",
    "# mean = mean / len(fgadr_full_loader.dataset)\n",
    "\n",
    "# var = 0.0\n",
    "# for datas in fgadr_full_loader:\n",
    "#     images, labels = datas\n",
    "#     batch_samples = images.size(0)\n",
    "# #     images = data['images']\n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "#     var += ((images - mean.unsqueeze(1)) ** 2).sum([0, 2])\n",
    "\n",
    "# std = torch.sqrt(var / (len(fgadr_full_loader.dataset) * 224 * 224))\n",
    "\n",
    "# print(len(fgadr_full_loader.dataset))\n",
    "# print(\"Mean and std: \", mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6bb1e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datas in train_loader:\n",
    "#     img, label = datas\n",
    "#     print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ffac6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 150\n",
    "def train_function(model, train_loader='', val_loader='', test_loader='', train=True, save_model_path='model.ckpt'):\n",
    "    \n",
    "    if train:\n",
    "#         model.apply(weights_init)\n",
    "\n",
    "\n",
    "        # Loss and optimizer\n",
    "        c_weight = torch.FloatTensor([0.235, 0.2225, 0.17, 0.16, 0.21250001]).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight = c_weight)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#         optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                             step_size=50, gamma=0.1)\n",
    "\n",
    "        # Train the model\n",
    "        lr = learning_rate\n",
    "        total_step = len(train_loader)\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                # Move tensors to the configured device\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "#                 outputs = model(images.view(batch_size, -1))\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "            # Code to update the lr\n",
    "#             lr *= learning_rate_decay\n",
    "#             update_lr(optimizer, lr)\n",
    "            exp_lr_scheduler.step()\n",
    "            \n",
    "            if epoch%2 == 0:\n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    for images, labels in val_loader:\n",
    "                        images = images.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "                        predicted = model(images)\n",
    "                        _, predicted = torch.max(predicted, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    print(' Lr: {} , Validataion accuracy is: {} %'.format(optimizer.param_groups[0]['lr'],(100 * correct / total)))\n",
    "\n",
    "\n",
    "                # Save the model checkpoint\n",
    "                torch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "    else:\n",
    "        # Run the test code once you have your by setting train flag to false\n",
    "        # and loading the best model\n",
    "\n",
    "        best_model = torch.load(save_model_path)\n",
    "        model.load_state_dict(best_model)\n",
    "        # Test the model\n",
    "        # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "\n",
    "                predicted = model(images)\n",
    "                _, predicted = torch.max(predicted, 1)\n",
    "\n",
    "\n",
    "                # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "#                 if total == 1000:\n",
    "#                     break\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509595bf",
   "metadata": {},
   "source": [
    "# Training on FGADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1cb2fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_to_save = 'fgadr_trained_model.ckpt'\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "num_features = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_features, 5)\n",
    "resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4443355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Step [10/23], Loss: 2.1629\n",
      "Epoch [1/150], Step [20/23], Loss: 1.3715\n",
      " Lr: 0.01 , Validataion accuracy is: 50.12787723785166 %\n",
      "Epoch [2/150], Step [10/23], Loss: 1.3581\n",
      "Epoch [2/150], Step [20/23], Loss: 1.3760\n",
      "Epoch [3/150], Step [10/23], Loss: 1.1503\n",
      "Epoch [3/150], Step [20/23], Loss: 1.1549\n",
      " Lr: 0.01 , Validataion accuracy is: 57.289002557544755 %\n",
      "Epoch [4/150], Step [10/23], Loss: 1.3042\n",
      "Epoch [4/150], Step [20/23], Loss: 1.1543\n",
      "Epoch [5/150], Step [10/23], Loss: 1.2099\n",
      "Epoch [5/150], Step [20/23], Loss: 1.1481\n",
      " Lr: 0.01 , Validataion accuracy is: 57.289002557544755 %\n",
      "Epoch [6/150], Step [10/23], Loss: 1.0719\n",
      "Epoch [6/150], Step [20/23], Loss: 1.2979\n",
      "Epoch [7/150], Step [10/23], Loss: 1.0051\n",
      "Epoch [7/150], Step [20/23], Loss: 0.9778\n",
      " Lr: 0.01 , Validataion accuracy is: 56.010230179028135 %\n",
      "Epoch [8/150], Step [10/23], Loss: 1.0685\n",
      "Epoch [8/150], Step [20/23], Loss: 1.1016\n",
      "Epoch [9/150], Step [10/23], Loss: 0.9890\n",
      "Epoch [9/150], Step [20/23], Loss: 1.0472\n",
      " Lr: 0.01 , Validataion accuracy is: 58.8235294117647 %\n",
      "Epoch [10/150], Step [10/23], Loss: 1.0577\n",
      "Epoch [10/150], Step [20/23], Loss: 1.1350\n",
      "Epoch [11/150], Step [10/23], Loss: 0.9207\n",
      "Epoch [11/150], Step [20/23], Loss: 1.1964\n",
      " Lr: 0.01 , Validataion accuracy is: 53.70843989769821 %\n",
      "Epoch [12/150], Step [10/23], Loss: 1.1420\n",
      "Epoch [12/150], Step [20/23], Loss: 0.9875\n",
      "Epoch [13/150], Step [10/23], Loss: 1.0056\n",
      "Epoch [13/150], Step [20/23], Loss: 1.1236\n",
      " Lr: 0.01 , Validataion accuracy is: 60.35805626598466 %\n",
      "Epoch [14/150], Step [10/23], Loss: 1.1798\n",
      "Epoch [14/150], Step [20/23], Loss: 0.9756\n",
      "Epoch [15/150], Step [10/23], Loss: 0.9680\n",
      "Epoch [15/150], Step [20/23], Loss: 1.0489\n",
      " Lr: 0.01 , Validataion accuracy is: 59.33503836317136 %\n",
      "Epoch [16/150], Step [10/23], Loss: 1.0088\n",
      "Epoch [16/150], Step [20/23], Loss: 1.0850\n",
      "Epoch [17/150], Step [10/23], Loss: 1.0604\n",
      "Epoch [17/150], Step [20/23], Loss: 0.9795\n",
      " Lr: 0.01 , Validataion accuracy is: 58.56777493606138 %\n",
      "Epoch [18/150], Step [10/23], Loss: 1.1458\n",
      "Epoch [18/150], Step [20/23], Loss: 1.2384\n",
      "Epoch [19/150], Step [10/23], Loss: 1.1377\n",
      "Epoch [19/150], Step [20/23], Loss: 1.1301\n",
      " Lr: 0.01 , Validataion accuracy is: 58.05626598465473 %\n",
      "Epoch [20/150], Step [10/23], Loss: 0.9387\n",
      "Epoch [20/150], Step [20/23], Loss: 1.0655\n",
      "Epoch [21/150], Step [10/23], Loss: 1.1593\n",
      "Epoch [21/150], Step [20/23], Loss: 1.1321\n",
      " Lr: 0.01 , Validataion accuracy is: 59.07928388746803 %\n",
      "Epoch [22/150], Step [10/23], Loss: 0.9352\n",
      "Epoch [22/150], Step [20/23], Loss: 0.9429\n",
      "Epoch [23/150], Step [10/23], Loss: 1.0600\n",
      "Epoch [23/150], Step [20/23], Loss: 0.9911\n",
      " Lr: 0.01 , Validataion accuracy is: 58.312020460358056 %\n",
      "Epoch [24/150], Step [10/23], Loss: 1.1580\n",
      "Epoch [24/150], Step [20/23], Loss: 1.0734\n",
      "Epoch [25/150], Step [10/23], Loss: 1.1080\n",
      "Epoch [25/150], Step [20/23], Loss: 0.9860\n",
      " Lr: 0.01 , Validataion accuracy is: 60.10230179028133 %\n",
      "Epoch [26/150], Step [10/23], Loss: 1.0573\n",
      "Epoch [26/150], Step [20/23], Loss: 0.9676\n",
      "Epoch [27/150], Step [10/23], Loss: 0.9728\n",
      "Epoch [27/150], Step [20/23], Loss: 1.1296\n",
      " Lr: 0.01 , Validataion accuracy is: 58.8235294117647 %\n",
      "Epoch [28/150], Step [10/23], Loss: 1.0990\n",
      "Epoch [28/150], Step [20/23], Loss: 1.2210\n",
      "Epoch [29/150], Step [10/23], Loss: 0.9933\n",
      "Epoch [29/150], Step [20/23], Loss: 0.9676\n",
      " Lr: 0.01 , Validataion accuracy is: 54.47570332480819 %\n",
      "Epoch [30/150], Step [10/23], Loss: 1.1594\n",
      "Epoch [30/150], Step [20/23], Loss: 0.9902\n",
      "Epoch [31/150], Step [10/23], Loss: 1.2471\n",
      "Epoch [31/150], Step [20/23], Loss: 0.9470\n",
      " Lr: 0.01 , Validataion accuracy is: 59.846547314578004 %\n",
      "Epoch [32/150], Step [10/23], Loss: 0.9184\n",
      "Epoch [32/150], Step [20/23], Loss: 0.8935\n",
      "Epoch [33/150], Step [10/23], Loss: 0.8405\n",
      "Epoch [33/150], Step [20/23], Loss: 0.9770\n",
      " Lr: 0.01 , Validataion accuracy is: 59.33503836317136 %\n",
      "Epoch [34/150], Step [10/23], Loss: 0.9058\n",
      "Epoch [34/150], Step [20/23], Loss: 1.0933\n",
      "Epoch [35/150], Step [10/23], Loss: 1.0060\n",
      "Epoch [35/150], Step [20/23], Loss: 0.9559\n",
      " Lr: 0.01 , Validataion accuracy is: 59.59079283887468 %\n",
      "Epoch [36/150], Step [10/23], Loss: 1.0677\n",
      "Epoch [36/150], Step [20/23], Loss: 0.9909\n",
      "Epoch [37/150], Step [10/23], Loss: 0.8451\n",
      "Epoch [37/150], Step [20/23], Loss: 1.0081\n",
      " Lr: 0.01 , Validataion accuracy is: 60.869565217391305 %\n",
      "Epoch [38/150], Step [10/23], Loss: 1.0498\n",
      "Epoch [38/150], Step [20/23], Loss: 1.0005\n",
      "Epoch [39/150], Step [10/23], Loss: 0.9569\n",
      "Epoch [39/150], Step [20/23], Loss: 0.9249\n",
      " Lr: 0.01 , Validataion accuracy is: 58.8235294117647 %\n",
      "Epoch [40/150], Step [10/23], Loss: 1.1351\n",
      "Epoch [40/150], Step [20/23], Loss: 0.8674\n",
      "Epoch [41/150], Step [10/23], Loss: 1.0088\n",
      "Epoch [41/150], Step [20/23], Loss: 0.7982\n",
      " Lr: 0.01 , Validataion accuracy is: 60.869565217391305 %\n",
      "Epoch [42/150], Step [10/23], Loss: 0.7948\n",
      "Epoch [42/150], Step [20/23], Loss: 1.0363\n",
      "Epoch [43/150], Step [10/23], Loss: 0.9786\n",
      "Epoch [43/150], Step [20/23], Loss: 0.7492\n",
      " Lr: 0.01 , Validataion accuracy is: 60.35805626598466 %\n",
      "Epoch [44/150], Step [10/23], Loss: 0.8589\n",
      "Epoch [44/150], Step [20/23], Loss: 0.9606\n",
      "Epoch [45/150], Step [10/23], Loss: 0.9467\n",
      "Epoch [45/150], Step [20/23], Loss: 0.8954\n",
      " Lr: 0.01 , Validataion accuracy is: 59.07928388746803 %\n",
      "Epoch [46/150], Step [10/23], Loss: 0.9030\n",
      "Epoch [46/150], Step [20/23], Loss: 0.9904\n",
      "Epoch [47/150], Step [10/23], Loss: 1.0553\n",
      "Epoch [47/150], Step [20/23], Loss: 0.8854\n",
      " Lr: 0.01 , Validataion accuracy is: 58.56777493606138 %\n",
      "Epoch [48/150], Step [10/23], Loss: 1.0643\n",
      "Epoch [48/150], Step [20/23], Loss: 0.9446\n",
      "Epoch [49/150], Step [10/23], Loss: 0.9000\n",
      "Epoch [49/150], Step [20/23], Loss: 1.0840\n",
      " Lr: 0.01 , Validataion accuracy is: 59.07928388746803 %\n",
      "Epoch [50/150], Step [10/23], Loss: 0.9389\n",
      "Epoch [50/150], Step [20/23], Loss: 0.8526\n",
      "Epoch [51/150], Step [10/23], Loss: 0.9321\n",
      "Epoch [51/150], Step [20/23], Loss: 0.9046\n",
      " Lr: 0.001 , Validataion accuracy is: 60.35805626598466 %\n",
      "Epoch [52/150], Step [10/23], Loss: 0.9879\n",
      "Epoch [52/150], Step [20/23], Loss: 0.7837\n",
      "Epoch [53/150], Step [10/23], Loss: 0.9333\n",
      "Epoch [53/150], Step [20/23], Loss: 0.8540\n",
      " Lr: 0.001 , Validataion accuracy is: 61.12531969309463 %\n",
      "Epoch [54/150], Step [10/23], Loss: 0.8261\n",
      "Epoch [54/150], Step [20/23], Loss: 0.8644\n",
      "Epoch [55/150], Step [10/23], Loss: 0.9205\n",
      "Epoch [55/150], Step [20/23], Loss: 0.8821\n",
      " Lr: 0.001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [56/150], Step [10/23], Loss: 0.8641\n",
      "Epoch [56/150], Step [20/23], Loss: 0.8665\n",
      "Epoch [57/150], Step [10/23], Loss: 0.9458\n",
      "Epoch [57/150], Step [20/23], Loss: 0.8670\n",
      " Lr: 0.001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [58/150], Step [10/23], Loss: 0.7897\n",
      "Epoch [58/150], Step [20/23], Loss: 0.8872\n",
      "Epoch [59/150], Step [10/23], Loss: 0.9735\n",
      "Epoch [59/150], Step [20/23], Loss: 0.8677\n",
      " Lr: 0.001 , Validataion accuracy is: 57.80051150895141 %\n",
      "Epoch [60/150], Step [10/23], Loss: 0.9034\n",
      "Epoch [60/150], Step [20/23], Loss: 0.8831\n",
      "Epoch [61/150], Step [10/23], Loss: 0.9108\n",
      "Epoch [61/150], Step [20/23], Loss: 0.8085\n",
      " Lr: 0.001 , Validataion accuracy is: 59.07928388746803 %\n",
      "Epoch [62/150], Step [10/23], Loss: 0.7759\n",
      "Epoch [62/150], Step [20/23], Loss: 0.9140\n",
      "Epoch [63/150], Step [10/23], Loss: 0.8819\n",
      "Epoch [63/150], Step [20/23], Loss: 0.8250\n",
      " Lr: 0.001 , Validataion accuracy is: 58.56777493606138 %\n",
      "Epoch [64/150], Step [10/23], Loss: 0.8234\n",
      "Epoch [64/150], Step [20/23], Loss: 0.8297\n",
      "Epoch [65/150], Step [10/23], Loss: 0.8392\n",
      "Epoch [65/150], Step [20/23], Loss: 0.8143\n",
      " Lr: 0.001 , Validataion accuracy is: 56.52173913043478 %\n",
      "Epoch [66/150], Step [10/23], Loss: 0.7262\n",
      "Epoch [66/150], Step [20/23], Loss: 0.8657\n",
      "Epoch [67/150], Step [10/23], Loss: 0.8007\n",
      "Epoch [67/150], Step [20/23], Loss: 0.7192\n",
      " Lr: 0.001 , Validataion accuracy is: 59.33503836317136 %\n",
      "Epoch [68/150], Step [10/23], Loss: 0.7235\n",
      "Epoch [68/150], Step [20/23], Loss: 0.9870\n",
      "Epoch [69/150], Step [10/23], Loss: 0.7983\n",
      "Epoch [69/150], Step [20/23], Loss: 0.8024\n",
      " Lr: 0.001 , Validataion accuracy is: 58.56777493606138 %\n",
      "Epoch [70/150], Step [10/23], Loss: 0.9313\n",
      "Epoch [70/150], Step [20/23], Loss: 0.7116\n",
      "Epoch [71/150], Step [10/23], Loss: 0.6796\n",
      "Epoch [71/150], Step [20/23], Loss: 0.9286\n",
      " Lr: 0.001 , Validataion accuracy is: 60.869565217391305 %\n",
      "Epoch [72/150], Step [10/23], Loss: 0.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/150], Step [20/23], Loss: 0.5811\n",
      "Epoch [73/150], Step [10/23], Loss: 0.7261\n",
      "Epoch [73/150], Step [20/23], Loss: 0.7159\n",
      " Lr: 0.001 , Validataion accuracy is: 60.10230179028133 %\n",
      "Epoch [74/150], Step [10/23], Loss: 0.9395\n",
      "Epoch [74/150], Step [20/23], Loss: 0.7191\n",
      "Epoch [75/150], Step [10/23], Loss: 0.6858\n",
      "Epoch [75/150], Step [20/23], Loss: 0.6199\n",
      " Lr: 0.001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [76/150], Step [10/23], Loss: 0.7608\n",
      "Epoch [76/150], Step [20/23], Loss: 0.8014\n",
      "Epoch [77/150], Step [10/23], Loss: 0.6667\n",
      "Epoch [77/150], Step [20/23], Loss: 0.6201\n",
      " Lr: 0.001 , Validataion accuracy is: 57.289002557544755 %\n",
      "Epoch [78/150], Step [10/23], Loss: 0.7694\n",
      "Epoch [78/150], Step [20/23], Loss: 0.7811\n",
      "Epoch [79/150], Step [10/23], Loss: 0.6808\n",
      "Epoch [79/150], Step [20/23], Loss: 0.7646\n",
      " Lr: 0.001 , Validataion accuracy is: 58.05626598465473 %\n",
      "Epoch [80/150], Step [10/23], Loss: 0.6904\n",
      "Epoch [80/150], Step [20/23], Loss: 0.7187\n",
      "Epoch [81/150], Step [10/23], Loss: 0.6863\n",
      "Epoch [81/150], Step [20/23], Loss: 0.8794\n",
      " Lr: 0.001 , Validataion accuracy is: 59.07928388746803 %\n",
      "Epoch [82/150], Step [10/23], Loss: 0.7577\n",
      "Epoch [82/150], Step [20/23], Loss: 0.6720\n",
      "Epoch [83/150], Step [10/23], Loss: 0.6755\n",
      "Epoch [83/150], Step [20/23], Loss: 0.8006\n",
      " Lr: 0.001 , Validataion accuracy is: 60.10230179028133 %\n",
      "Epoch [84/150], Step [10/23], Loss: 0.6412\n",
      "Epoch [84/150], Step [20/23], Loss: 0.9029\n",
      "Epoch [85/150], Step [10/23], Loss: 0.8928\n",
      "Epoch [85/150], Step [20/23], Loss: 0.8252\n",
      " Lr: 0.001 , Validataion accuracy is: 58.8235294117647 %\n",
      "Epoch [86/150], Step [10/23], Loss: 0.5563\n",
      "Epoch [86/150], Step [20/23], Loss: 0.8844\n",
      "Epoch [87/150], Step [10/23], Loss: 0.6097\n",
      "Epoch [87/150], Step [20/23], Loss: 0.7362\n",
      " Lr: 0.001 , Validataion accuracy is: 60.869565217391305 %\n",
      "Epoch [88/150], Step [10/23], Loss: 0.5165\n",
      "Epoch [88/150], Step [20/23], Loss: 0.6983\n",
      "Epoch [89/150], Step [10/23], Loss: 0.7000\n",
      "Epoch [89/150], Step [20/23], Loss: 0.6549\n",
      " Lr: 0.001 , Validataion accuracy is: 57.54475703324808 %\n",
      "Epoch [90/150], Step [10/23], Loss: 0.7595\n",
      "Epoch [90/150], Step [20/23], Loss: 0.6531\n",
      "Epoch [91/150], Step [10/23], Loss: 0.6142\n",
      "Epoch [91/150], Step [20/23], Loss: 0.5699\n",
      " Lr: 0.001 , Validataion accuracy is: 60.10230179028133 %\n",
      "Epoch [92/150], Step [10/23], Loss: 0.6564\n",
      "Epoch [92/150], Step [20/23], Loss: 0.5302\n",
      "Epoch [93/150], Step [10/23], Loss: 0.5825\n",
      "Epoch [93/150], Step [20/23], Loss: 0.4791\n",
      " Lr: 0.001 , Validataion accuracy is: 58.56777493606138 %\n",
      "Epoch [94/150], Step [10/23], Loss: 0.8518\n",
      "Epoch [94/150], Step [20/23], Loss: 0.6334\n",
      "Epoch [95/150], Step [10/23], Loss: 0.5739\n",
      "Epoch [95/150], Step [20/23], Loss: 0.6015\n",
      " Lr: 0.001 , Validataion accuracy is: 60.10230179028133 %\n",
      "Epoch [96/150], Step [10/23], Loss: 0.6182\n",
      "Epoch [96/150], Step [20/23], Loss: 0.6310\n",
      "Epoch [97/150], Step [10/23], Loss: 0.4834\n",
      "Epoch [97/150], Step [20/23], Loss: 0.6260\n",
      " Lr: 0.001 , Validataion accuracy is: 60.869565217391305 %\n",
      "Epoch [98/150], Step [10/23], Loss: 0.6139\n",
      "Epoch [98/150], Step [20/23], Loss: 0.4952\n",
      "Epoch [99/150], Step [10/23], Loss: 0.5798\n",
      "Epoch [99/150], Step [20/23], Loss: 0.5834\n",
      " Lr: 0.001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [100/150], Step [10/23], Loss: 0.3695\n",
      "Epoch [100/150], Step [20/23], Loss: 0.4440\n",
      "Epoch [101/150], Step [10/23], Loss: 0.6191\n",
      "Epoch [101/150], Step [20/23], Loss: 0.4804\n",
      " Lr: 0.0001 , Validataion accuracy is: 59.846547314578004 %\n",
      "Epoch [102/150], Step [10/23], Loss: 0.4038\n",
      "Epoch [102/150], Step [20/23], Loss: 0.4199\n",
      "Epoch [103/150], Step [10/23], Loss: 0.5494\n",
      "Epoch [103/150], Step [20/23], Loss: 0.4398\n",
      " Lr: 0.0001 , Validataion accuracy is: 59.33503836317136 %\n",
      "Epoch [104/150], Step [10/23], Loss: 0.5073\n",
      "Epoch [104/150], Step [20/23], Loss: 0.4455\n",
      "Epoch [105/150], Step [10/23], Loss: 0.4306\n",
      "Epoch [105/150], Step [20/23], Loss: 0.4022\n",
      " Lr: 0.0001 , Validataion accuracy is: 59.59079283887468 %\n",
      "Epoch [106/150], Step [10/23], Loss: 0.3440\n",
      "Epoch [106/150], Step [20/23], Loss: 0.5048\n",
      "Epoch [107/150], Step [10/23], Loss: 0.4447\n",
      "Epoch [107/150], Step [20/23], Loss: 0.4301\n",
      " Lr: 0.0001 , Validataion accuracy is: 58.8235294117647 %\n",
      "Epoch [108/150], Step [10/23], Loss: 0.4268\n",
      "Epoch [108/150], Step [20/23], Loss: 0.4879\n",
      "Epoch [109/150], Step [10/23], Loss: 0.3038\n",
      "Epoch [109/150], Step [20/23], Loss: 0.3954\n",
      " Lr: 0.0001 , Validataion accuracy is: 59.846547314578004 %\n",
      "Epoch [110/150], Step [10/23], Loss: 0.3805\n",
      "Epoch [110/150], Step [20/23], Loss: 0.3362\n",
      "Epoch [111/150], Step [10/23], Loss: 0.3727\n",
      "Epoch [111/150], Step [20/23], Loss: 0.3407\n",
      " Lr: 0.0001 , Validataion accuracy is: 61.12531969309463 %\n",
      "Epoch [112/150], Step [10/23], Loss: 0.5544\n",
      "Epoch [112/150], Step [20/23], Loss: 0.5761\n",
      "Epoch [113/150], Step [10/23], Loss: 0.3037\n",
      "Epoch [113/150], Step [20/23], Loss: 0.3095\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.35805626598466 %\n",
      "Epoch [114/150], Step [10/23], Loss: 0.3865\n",
      "Epoch [114/150], Step [20/23], Loss: 0.3877\n",
      "Epoch [115/150], Step [10/23], Loss: 0.4598\n",
      "Epoch [115/150], Step [20/23], Loss: 0.4532\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [116/150], Step [10/23], Loss: 0.2568\n",
      "Epoch [116/150], Step [20/23], Loss: 0.2675\n",
      "Epoch [117/150], Step [10/23], Loss: 0.3991\n",
      "Epoch [117/150], Step [20/23], Loss: 0.2847\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.869565217391305 %\n",
      "Epoch [118/150], Step [10/23], Loss: 0.3339\n",
      "Epoch [118/150], Step [20/23], Loss: 0.3372\n",
      "Epoch [119/150], Step [10/23], Loss: 0.3075\n",
      "Epoch [119/150], Step [20/23], Loss: 0.3695\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [120/150], Step [10/23], Loss: 0.2817\n",
      "Epoch [120/150], Step [20/23], Loss: 0.2926\n",
      "Epoch [121/150], Step [10/23], Loss: 0.4723\n",
      "Epoch [121/150], Step [20/23], Loss: 0.7583\n",
      " Lr: 0.0001 , Validataion accuracy is: 61.12531969309463 %\n",
      "Epoch [122/150], Step [10/23], Loss: 0.3531\n",
      "Epoch [122/150], Step [20/23], Loss: 0.3861\n",
      "Epoch [123/150], Step [10/23], Loss: 0.2055\n",
      "Epoch [123/150], Step [20/23], Loss: 0.2106\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [124/150], Step [10/23], Loss: 0.2515\n",
      "Epoch [124/150], Step [20/23], Loss: 0.3219\n",
      "Epoch [125/150], Step [10/23], Loss: 0.2846\n",
      "Epoch [125/150], Step [20/23], Loss: 0.4732\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.10230179028133 %\n",
      "Epoch [126/150], Step [10/23], Loss: 0.3636\n",
      "Epoch [126/150], Step [20/23], Loss: 0.3695\n",
      "Epoch [127/150], Step [10/23], Loss: 0.2793\n",
      "Epoch [127/150], Step [20/23], Loss: 0.2388\n",
      " Lr: 0.0001 , Validataion accuracy is: 59.59079283887468 %\n",
      "Epoch [128/150], Step [10/23], Loss: 0.1926\n",
      "Epoch [128/150], Step [20/23], Loss: 0.2053\n",
      "Epoch [129/150], Step [10/23], Loss: 0.3349\n",
      "Epoch [129/150], Step [20/23], Loss: 0.1899\n",
      " Lr: 0.0001 , Validataion accuracy is: 59.846547314578004 %\n",
      "Epoch [130/150], Step [10/23], Loss: 0.3199\n",
      "Epoch [130/150], Step [20/23], Loss: 0.5021\n",
      "Epoch [131/150], Step [10/23], Loss: 0.2613\n",
      "Epoch [131/150], Step [20/23], Loss: 0.3804\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.10230179028133 %\n",
      "Epoch [132/150], Step [10/23], Loss: 0.2194\n",
      "Epoch [132/150], Step [20/23], Loss: 0.2309\n",
      "Epoch [133/150], Step [10/23], Loss: 0.3839\n",
      "Epoch [133/150], Step [20/23], Loss: 0.2747\n",
      " Lr: 0.0001 , Validataion accuracy is: 61.12531969309463 %\n",
      "Epoch [134/150], Step [10/23], Loss: 0.2221\n",
      "Epoch [134/150], Step [20/23], Loss: 0.2404\n",
      "Epoch [135/150], Step [10/23], Loss: 0.1617\n",
      "Epoch [135/150], Step [20/23], Loss: 0.1955\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.35805626598466 %\n",
      "Epoch [136/150], Step [10/23], Loss: 0.2021\n",
      "Epoch [136/150], Step [20/23], Loss: 0.2794\n",
      "Epoch [137/150], Step [10/23], Loss: 0.3663\n",
      "Epoch [137/150], Step [20/23], Loss: 0.2674\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.35805626598466 %\n",
      "Epoch [138/150], Step [10/23], Loss: 0.2450\n",
      "Epoch [138/150], Step [20/23], Loss: 0.2775\n",
      "Epoch [139/150], Step [10/23], Loss: 0.2686\n",
      "Epoch [139/150], Step [20/23], Loss: 0.1673\n",
      " Lr: 0.0001 , Validataion accuracy is: 61.892583120204606 %\n",
      "Epoch [140/150], Step [10/23], Loss: 0.1917\n",
      "Epoch [140/150], Step [20/23], Loss: 0.4622\n",
      "Epoch [141/150], Step [10/23], Loss: 0.3584\n",
      "Epoch [141/150], Step [20/23], Loss: 0.2339\n",
      " Lr: 0.0001 , Validataion accuracy is: 58.8235294117647 %\n",
      "Epoch [142/150], Step [10/23], Loss: 0.1799\n",
      "Epoch [142/150], Step [20/23], Loss: 0.3493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/150], Step [10/23], Loss: 0.3175\n",
      "Epoch [143/150], Step [20/23], Loss: 0.2339\n",
      " Lr: 0.0001 , Validataion accuracy is: 59.846547314578004 %\n",
      "Epoch [144/150], Step [10/23], Loss: 0.2256\n",
      "Epoch [144/150], Step [20/23], Loss: 0.2854\n",
      "Epoch [145/150], Step [10/23], Loss: 0.2046\n",
      "Epoch [145/150], Step [20/23], Loss: 0.1638\n",
      " Lr: 0.0001 , Validataion accuracy is: 60.61381074168798 %\n",
      "Epoch [146/150], Step [10/23], Loss: 0.1460\n",
      "Epoch [146/150], Step [20/23], Loss: 0.2296\n",
      "Epoch [147/150], Step [10/23], Loss: 0.1361\n",
      "Epoch [147/150], Step [20/23], Loss: 0.2083\n",
      " Lr: 0.0001 , Validataion accuracy is: 61.12531969309463 %\n",
      "Epoch [148/150], Step [10/23], Loss: 0.1515\n",
      "Epoch [148/150], Step [20/23], Loss: 0.1413\n",
      "Epoch [149/150], Step [10/23], Loss: 0.2162\n",
      "Epoch [149/150], Step [20/23], Loss: 0.2822\n",
      " Lr: 0.0001 , Validataion accuracy is: 58.05626598465473 %\n",
      "Epoch [150/150], Step [10/23], Loss: 0.1691\n",
      "Epoch [150/150], Step [20/23], Loss: 0.2680\n"
     ]
    }
   ],
   "source": [
    "train_function(resnet18, train_loader=f_train_loader, val_loader=f_val_loader, test_loader='', train=True, save_model_path=model_path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b2d3d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 164 464 521 217\n"
     ]
    }
   ],
   "source": [
    "cl_0 = 0\n",
    "cl_1 = 0\n",
    "cl_2 = 0\n",
    "cl_3 = 0\n",
    "cl_4 = 0\n",
    "for data in f_train_loader:\n",
    "    img, label = data\n",
    "    for lbl in label:\n",
    "        if lbl == 0:\n",
    "            cl_0 += 1\n",
    "        elif lbl == 1:\n",
    "            cl_1 += 1\n",
    "        elif lbl == 2:\n",
    "            cl_2 += 1\n",
    "        elif lbl == 3:\n",
    "            cl_3 += 1\n",
    "        elif lbl == 4:\n",
    "            cl_4 += 1\n",
    "            \n",
    "print(cl_0, cl_1, cl_2, cl_3, cl_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "869731a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.235     , 0.2225    , 0.17      , 0.16      , 0.21250001]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_list = [84, 164, 464, 521, 217]\n",
    "weight_tensor = torch.zeros(1,5)\n",
    "for idx in range(len(val_list)):\n",
    "    wt = val_list[idx] / len(f_train_loader.dataset)\n",
    "#     print(len(data_file))\n",
    "    weight_tensor[0][idx] = round((1 - wt), 2)\n",
    "    \n",
    "from sklearn.preprocessing import normalize\n",
    "normalize(weight_tensor, norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e312cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 48 131 125 70\n"
     ]
    }
   ],
   "source": [
    "cl_0 = 0\n",
    "cl_1 = 0\n",
    "cl_2 = 0\n",
    "cl_3 = 0\n",
    "cl_4 = 0\n",
    "for data in f_val_loader:\n",
    "    img, label = data\n",
    "    for lbl in label:\n",
    "        if lbl == 0:\n",
    "            cl_0 += 1\n",
    "        elif lbl == 1:\n",
    "            cl_1 += 1\n",
    "        elif lbl == 2:\n",
    "            cl_2 += 1\n",
    "        elif lbl == 3:\n",
    "            cl_3 += 1\n",
    "        elif lbl == 4:\n",
    "            cl_4 += 1\n",
    "            \n",
    "print(cl_0, cl_1, cl_2, cl_3, cl_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "493968bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 15315 test images: 16.643813254978777 %\n"
     ]
    }
   ],
   "source": [
    "train_function(resnet18, test_loader=k_full_loader, train=False, save_model_path=model_path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c0cbade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  KaggleR\n",
      "Dataset Name:  KaggleR\n",
      "Dataset Name:  KaggleR\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82192a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10721"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96e670a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2297 test images: 27.514148889856333 %\n"
     ]
    }
   ],
   "source": [
    "# train_function(resnet18, test_loader=k_test_loader, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c9c7fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10721 test images: 14.718776233560302 %\n"
     ]
    }
   ],
   "source": [
    "# train_function(resnet18, test_loader=k_train_loader, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192c231",
   "metadata": {},
   "source": [
    "# Kaggle model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "11724b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_model_path_to_save = 'kaggle_trained_model.ckpt'\n",
    "k_resnet18 = models.resnet18(pretrained=True)\n",
    "num_features = k_resnet18.fc.in_features\n",
    "k_resnet18.fc = nn.Linear(num_features, 5)\n",
    "k_resnet18.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d32240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Step [10/168], Loss: 1.6579\n",
      "Epoch [1/150], Step [20/168], Loss: 0.8643\n",
      "Epoch [1/150], Step [30/168], Loss: 0.6707\n",
      "Epoch [1/150], Step [40/168], Loss: 1.0035\n",
      "Epoch [1/150], Step [50/168], Loss: 0.6731\n",
      "Epoch [1/150], Step [60/168], Loss: 0.9568\n",
      "Epoch [1/150], Step [70/168], Loss: 0.6245\n",
      "Epoch [1/150], Step [80/168], Loss: 0.5826\n",
      "Epoch [1/150], Step [90/168], Loss: 0.6032\n",
      "Epoch [1/150], Step [100/168], Loss: 0.8267\n",
      "Epoch [1/150], Step [110/168], Loss: 0.6488\n",
      "Epoch [1/150], Step [120/168], Loss: 0.6168\n",
      "Epoch [1/150], Step [130/168], Loss: 2.7461\n",
      "Epoch [1/150], Step [140/168], Loss: 1.0346\n",
      "Epoch [1/150], Step [150/168], Loss: 1.2063\n",
      "Epoch [1/150], Step [160/168], Loss: 1.2759\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [2/150], Step [10/168], Loss: 1.6273\n",
      "Epoch [2/150], Step [20/168], Loss: 1.0229\n",
      "Epoch [2/150], Step [30/168], Loss: 0.5721\n",
      "Epoch [2/150], Step [40/168], Loss: 0.7239\n",
      "Epoch [2/150], Step [50/168], Loss: 0.6368\n",
      "Epoch [2/150], Step [60/168], Loss: 0.7802\n",
      "Epoch [2/150], Step [70/168], Loss: 0.6536\n",
      "Epoch [2/150], Step [80/168], Loss: 0.5844\n",
      "Epoch [2/150], Step [90/168], Loss: 0.4954\n",
      "Epoch [2/150], Step [100/168], Loss: 0.7645\n",
      "Epoch [2/150], Step [110/168], Loss: 0.6622\n",
      "Epoch [2/150], Step [120/168], Loss: 0.6682\n",
      "Epoch [2/150], Step [130/168], Loss: 2.3001\n",
      "Epoch [2/150], Step [140/168], Loss: 1.3488\n",
      "Epoch [2/150], Step [150/168], Loss: 1.2888\n",
      "Epoch [2/150], Step [160/168], Loss: 1.3251\n",
      "Epoch [3/150], Step [10/168], Loss: 1.6198\n",
      "Epoch [3/150], Step [20/168], Loss: 0.9693\n",
      "Epoch [3/150], Step [30/168], Loss: 0.7410\n",
      "Epoch [3/150], Step [40/168], Loss: 0.7514\n",
      "Epoch [3/150], Step [50/168], Loss: 0.6576\n",
      "Epoch [3/150], Step [60/168], Loss: 0.7800\n",
      "Epoch [3/150], Step [70/168], Loss: 0.6625\n",
      "Epoch [3/150], Step [80/168], Loss: 0.5561\n",
      "Epoch [3/150], Step [90/168], Loss: 0.5007\n",
      "Epoch [3/150], Step [100/168], Loss: 0.7900\n",
      "Epoch [3/150], Step [110/168], Loss: 0.6826\n",
      "Epoch [3/150], Step [120/168], Loss: 0.6304\n",
      "Epoch [3/150], Step [130/168], Loss: 2.3678\n",
      "Epoch [3/150], Step [140/168], Loss: 1.2759\n",
      "Epoch [3/150], Step [150/168], Loss: 1.2122\n",
      "Epoch [3/150], Step [160/168], Loss: 1.2574\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [4/150], Step [10/168], Loss: 1.6042\n",
      "Epoch [4/150], Step [20/168], Loss: 0.9225\n",
      "Epoch [4/150], Step [30/168], Loss: 0.5752\n",
      "Epoch [4/150], Step [40/168], Loss: 0.7517\n",
      "Epoch [4/150], Step [50/168], Loss: 0.6663\n",
      "Epoch [4/150], Step [60/168], Loss: 0.7774\n",
      "Epoch [4/150], Step [70/168], Loss: 0.6648\n",
      "Epoch [4/150], Step [80/168], Loss: 0.5424\n",
      "Epoch [4/150], Step [90/168], Loss: 0.5105\n",
      "Epoch [4/150], Step [100/168], Loss: 0.7563\n",
      "Epoch [4/150], Step [110/168], Loss: 0.6660\n",
      "Epoch [4/150], Step [120/168], Loss: 0.6465\n",
      "Epoch [4/150], Step [130/168], Loss: 2.3770\n",
      "Epoch [4/150], Step [140/168], Loss: 1.4320\n",
      "Epoch [4/150], Step [150/168], Loss: 1.2477\n",
      "Epoch [4/150], Step [160/168], Loss: 1.2777\n",
      "Epoch [5/150], Step [10/168], Loss: 2.4219\n",
      "Epoch [5/150], Step [20/168], Loss: 1.2409\n",
      "Epoch [5/150], Step [30/168], Loss: 0.7694\n",
      "Epoch [5/150], Step [40/168], Loss: 0.7313\n",
      "Epoch [5/150], Step [50/168], Loss: 0.6536\n",
      "Epoch [5/150], Step [60/168], Loss: 0.7776\n",
      "Epoch [5/150], Step [70/168], Loss: 0.6581\n",
      "Epoch [5/150], Step [80/168], Loss: 0.5600\n",
      "Epoch [5/150], Step [90/168], Loss: 0.4928\n",
      "Epoch [5/150], Step [100/168], Loss: 0.7734\n",
      "Epoch [5/150], Step [110/168], Loss: 0.6765\n",
      "Epoch [5/150], Step [120/168], Loss: 0.6157\n",
      "Epoch [5/150], Step [130/168], Loss: 2.3283\n",
      "Epoch [5/150], Step [140/168], Loss: 1.5880\n",
      "Epoch [5/150], Step [150/168], Loss: 1.3262\n",
      "Epoch [5/150], Step [160/168], Loss: 1.3173\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [6/150], Step [10/168], Loss: 1.1041\n",
      "Epoch [6/150], Step [20/168], Loss: 0.9629\n",
      "Epoch [6/150], Step [30/168], Loss: 0.5998\n",
      "Epoch [6/150], Step [40/168], Loss: 0.7329\n",
      "Epoch [6/150], Step [50/168], Loss: 0.6424\n",
      "Epoch [6/150], Step [60/168], Loss: 0.7663\n",
      "Epoch [6/150], Step [70/168], Loss: 0.6621\n",
      "Epoch [6/150], Step [80/168], Loss: 0.5536\n",
      "Epoch [6/150], Step [90/168], Loss: 0.4995\n",
      "Epoch [6/150], Step [100/168], Loss: 0.8093\n",
      "Epoch [6/150], Step [110/168], Loss: 0.6535\n",
      "Epoch [6/150], Step [120/168], Loss: 0.6181\n",
      "Epoch [6/150], Step [130/168], Loss: 2.2593\n",
      "Epoch [6/150], Step [140/168], Loss: 1.6161\n",
      "Epoch [6/150], Step [150/168], Loss: 1.3924\n",
      "Epoch [6/150], Step [160/168], Loss: 1.2888\n",
      "Epoch [7/150], Step [10/168], Loss: 0.4999\n",
      "Epoch [7/150], Step [20/168], Loss: 0.8268\n",
      "Epoch [7/150], Step [30/168], Loss: 0.6043\n",
      "Epoch [7/150], Step [40/168], Loss: 0.7249\n",
      "Epoch [7/150], Step [50/168], Loss: 0.6676\n",
      "Epoch [7/150], Step [60/168], Loss: 0.8258\n",
      "Epoch [7/150], Step [70/168], Loss: 0.6309\n",
      "Epoch [7/150], Step [80/168], Loss: 0.5943\n",
      "Epoch [7/150], Step [90/168], Loss: 0.4941\n",
      "Epoch [7/150], Step [100/168], Loss: 0.8494\n",
      "Epoch [7/150], Step [110/168], Loss: 0.6443\n",
      "Epoch [7/150], Step [120/168], Loss: 0.6401\n",
      "Epoch [7/150], Step [130/168], Loss: 2.2141\n",
      "Epoch [7/150], Step [140/168], Loss: 1.3646\n",
      "Epoch [7/150], Step [150/168], Loss: 1.2591\n",
      "Epoch [7/150], Step [160/168], Loss: 1.2601\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [8/150], Step [10/168], Loss: 1.0742\n",
      "Epoch [8/150], Step [20/168], Loss: 0.8569\n",
      "Epoch [8/150], Step [30/168], Loss: 0.5839\n",
      "Epoch [8/150], Step [40/168], Loss: 0.7259\n",
      "Epoch [8/150], Step [50/168], Loss: 0.6481\n",
      "Epoch [8/150], Step [60/168], Loss: 0.7866\n",
      "Epoch [8/150], Step [70/168], Loss: 0.6622\n",
      "Epoch [8/150], Step [80/168], Loss: 0.5480\n",
      "Epoch [8/150], Step [90/168], Loss: 0.5073\n",
      "Epoch [8/150], Step [100/168], Loss: 0.8033\n",
      "Epoch [8/150], Step [110/168], Loss: 0.6489\n",
      "Epoch [8/150], Step [120/168], Loss: 0.6301\n",
      "Epoch [8/150], Step [130/168], Loss: 2.2155\n",
      "Epoch [8/150], Step [140/168], Loss: 1.4698\n",
      "Epoch [8/150], Step [150/168], Loss: 1.5049\n",
      "Epoch [8/150], Step [160/168], Loss: 1.3476\n",
      "Epoch [9/150], Step [10/168], Loss: 1.1821\n",
      "Epoch [9/150], Step [20/168], Loss: 0.9546\n",
      "Epoch [9/150], Step [30/168], Loss: 0.5917\n",
      "Epoch [9/150], Step [40/168], Loss: 0.7235\n",
      "Epoch [9/150], Step [50/168], Loss: 0.6426\n",
      "Epoch [9/150], Step [60/168], Loss: 0.7718\n",
      "Epoch [9/150], Step [70/168], Loss: 0.6547\n",
      "Epoch [9/150], Step [80/168], Loss: 0.5412\n",
      "Epoch [9/150], Step [90/168], Loss: 0.5110\n",
      "Epoch [9/150], Step [100/168], Loss: 0.7907\n",
      "Epoch [9/150], Step [110/168], Loss: 0.6688\n",
      "Epoch [9/150], Step [120/168], Loss: 0.6226\n",
      "Epoch [9/150], Step [130/168], Loss: 2.2888\n",
      "Epoch [9/150], Step [140/168], Loss: 1.3850\n",
      "Epoch [9/150], Step [150/168], Loss: 1.4743\n",
      "Epoch [9/150], Step [160/168], Loss: 1.4870\n",
      " Lr: 0.01 , Validataion accuracy is: 55.85546364823683 %\n",
      "Epoch [10/150], Step [10/168], Loss: 1.5558\n",
      "Epoch [10/150], Step [20/168], Loss: 1.2958\n",
      "Epoch [10/150], Step [30/168], Loss: 1.1786\n",
      "Epoch [10/150], Step [40/168], Loss: 1.0080\n",
      "Epoch [10/150], Step [50/168], Loss: 0.8724\n",
      "Epoch [10/150], Step [60/168], Loss: 0.8916\n",
      "Epoch [10/150], Step [70/168], Loss: 0.7724\n",
      "Epoch [10/150], Step [80/168], Loss: 0.6396\n",
      "Epoch [10/150], Step [90/168], Loss: 0.5789\n",
      "Epoch [10/150], Step [100/168], Loss: 0.7883\n",
      "Epoch [10/150], Step [110/168], Loss: 0.6609\n",
      "Epoch [10/150], Step [120/168], Loss: 0.6161\n",
      "Epoch [10/150], Step [130/168], Loss: 2.2816\n",
      "Epoch [10/150], Step [140/168], Loss: 1.9302\n",
      "Epoch [10/150], Step [150/168], Loss: 1.8769\n",
      "Epoch [10/150], Step [160/168], Loss: 1.7880\n",
      "Epoch [11/150], Step [10/168], Loss: 1.1362\n",
      "Epoch [11/150], Step [20/168], Loss: 1.0445\n",
      "Epoch [11/150], Step [30/168], Loss: 0.9356\n",
      "Epoch [11/150], Step [40/168], Loss: 0.8861\n",
      "Epoch [11/150], Step [50/168], Loss: 0.7686\n",
      "Epoch [11/150], Step [60/168], Loss: 0.8400\n",
      "Epoch [11/150], Step [70/168], Loss: 0.7299\n",
      "Epoch [11/150], Step [80/168], Loss: 0.6239\n",
      "Epoch [11/150], Step [90/168], Loss: 0.5997\n",
      "Epoch [11/150], Step [100/168], Loss: 0.8058\n",
      "Epoch [11/150], Step [110/168], Loss: 0.6928\n",
      "Epoch [11/150], Step [120/168], Loss: 0.6534\n",
      "Epoch [11/150], Step [130/168], Loss: 2.2634\n",
      "Epoch [11/150], Step [140/168], Loss: 2.1397\n",
      "Epoch [11/150], Step [150/168], Loss: 2.0871\n",
      "Epoch [11/150], Step [160/168], Loss: 1.9103\n",
      " Lr: 0.01 , Validataion accuracy is: 4.984762734000871 %\n",
      "Epoch [12/150], Step [10/168], Loss: 0.9999\n",
      "Epoch [12/150], Step [20/168], Loss: 0.9779\n",
      "Epoch [12/150], Step [30/168], Loss: 0.8796\n",
      "Epoch [12/150], Step [40/168], Loss: 0.8572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/150], Step [50/168], Loss: 0.7510\n",
      "Epoch [12/150], Step [60/168], Loss: 0.8343\n",
      "Epoch [12/150], Step [70/168], Loss: 0.7225\n",
      "Epoch [12/150], Step [80/168], Loss: 0.6193\n",
      "Epoch [12/150], Step [90/168], Loss: 0.5947\n",
      "Epoch [12/150], Step [100/168], Loss: 0.8055\n",
      "Epoch [12/150], Step [110/168], Loss: 0.6868\n",
      "Epoch [12/150], Step [120/168], Loss: 0.6539\n",
      "Epoch [12/150], Step [130/168], Loss: 2.2656\n",
      "Epoch [12/150], Step [140/168], Loss: 2.1450\n",
      "Epoch [12/150], Step [150/168], Loss: 2.0634\n",
      "Epoch [12/150], Step [160/168], Loss: 1.9638\n",
      "Epoch [13/150], Step [10/168], Loss: 0.9573\n",
      "Epoch [13/150], Step [20/168], Loss: 0.9878\n",
      "Epoch [13/150], Step [30/168], Loss: 0.8965\n",
      "Epoch [13/150], Step [40/168], Loss: 0.8744\n",
      "Epoch [13/150], Step [50/168], Loss: 0.7563\n",
      "Epoch [13/150], Step [60/168], Loss: 0.8412\n",
      "Epoch [13/150], Step [70/168], Loss: 0.7209\n",
      "Epoch [13/150], Step [80/168], Loss: 0.6263\n",
      "Epoch [13/150], Step [90/168], Loss: 0.5955\n",
      "Epoch [13/150], Step [100/168], Loss: 0.8058\n",
      "Epoch [13/150], Step [110/168], Loss: 0.6893\n",
      "Epoch [13/150], Step [120/168], Loss: 0.6550\n",
      "Epoch [13/150], Step [130/168], Loss: 2.2562\n",
      "Epoch [13/150], Step [140/168], Loss: 2.1362\n",
      "Epoch [13/150], Step [150/168], Loss: 2.0692\n",
      "Epoch [13/150], Step [160/168], Loss: 1.9583\n",
      " Lr: 0.01 , Validataion accuracy is: 12.559860687853723 %\n",
      "Epoch [14/150], Step [10/168], Loss: 0.9364\n",
      "Epoch [14/150], Step [20/168], Loss: 0.9655\n",
      "Epoch [14/150], Step [30/168], Loss: 0.8730\n",
      "Epoch [14/150], Step [40/168], Loss: 0.8566\n",
      "Epoch [14/150], Step [50/168], Loss: 0.7470\n",
      "Epoch [14/150], Step [60/168], Loss: 0.8340\n",
      "Epoch [14/150], Step [70/168], Loss: 0.7225\n",
      "Epoch [14/150], Step [80/168], Loss: 0.6222\n",
      "Epoch [14/150], Step [90/168], Loss: 0.5947\n",
      "Epoch [14/150], Step [100/168], Loss: 0.8129\n",
      "Epoch [14/150], Step [110/168], Loss: 0.6877\n",
      "Epoch [14/150], Step [120/168], Loss: 0.6647\n",
      "Epoch [14/150], Step [130/168], Loss: 2.2306\n",
      "Epoch [14/150], Step [140/168], Loss: 2.1235\n",
      "Epoch [14/150], Step [150/168], Loss: 2.0458\n",
      "Epoch [14/150], Step [160/168], Loss: 1.8851\n",
      "Epoch [15/150], Step [10/168], Loss: 1.0353\n",
      "Epoch [15/150], Step [20/168], Loss: 0.8845\n",
      "Epoch [15/150], Step [30/168], Loss: 0.7783\n",
      "Epoch [15/150], Step [40/168], Loss: 0.7591\n",
      "Epoch [15/150], Step [50/168], Loss: 0.6543\n",
      "Epoch [15/150], Step [60/168], Loss: 0.7728\n",
      "Epoch [15/150], Step [70/168], Loss: 0.6634\n",
      "Epoch [15/150], Step [80/168], Loss: 0.5549\n",
      "Epoch [15/150], Step [90/168], Loss: 0.5067\n",
      "Epoch [15/150], Step [100/168], Loss: 0.7949\n",
      "Epoch [15/150], Step [110/168], Loss: 0.6596\n",
      "Epoch [15/150], Step [120/168], Loss: 0.6261\n",
      "Epoch [15/150], Step [130/168], Loss: 2.3152\n",
      "Epoch [15/150], Step [140/168], Loss: 1.8725\n",
      "Epoch [15/150], Step [150/168], Loss: 1.8441\n",
      "Epoch [15/150], Step [160/168], Loss: 1.7920\n",
      " Lr: 0.01 , Validataion accuracy is: 7.771005659555943 %\n",
      "Epoch [16/150], Step [10/168], Loss: 1.1158\n",
      "Epoch [16/150], Step [20/168], Loss: 1.0484\n",
      "Epoch [16/150], Step [30/168], Loss: 0.9421\n",
      "Epoch [16/150], Step [40/168], Loss: 0.8881\n",
      "Epoch [16/150], Step [50/168], Loss: 0.7780\n",
      "Epoch [16/150], Step [60/168], Loss: 0.8503\n",
      "Epoch [16/150], Step [70/168], Loss: 0.7411\n",
      "Epoch [16/150], Step [80/168], Loss: 0.6412\n",
      "Epoch [16/150], Step [90/168], Loss: 0.5260\n",
      "Epoch [16/150], Step [100/168], Loss: 0.7969\n",
      "Epoch [16/150], Step [110/168], Loss: 0.6664\n",
      "Epoch [16/150], Step [120/168], Loss: 0.6197\n",
      "Epoch [16/150], Step [130/168], Loss: 2.2969\n",
      "Epoch [16/150], Step [140/168], Loss: 1.9439\n",
      "Epoch [16/150], Step [150/168], Loss: 1.9419\n",
      "Epoch [16/150], Step [160/168], Loss: 1.6260\n",
      "Epoch [17/150], Step [10/168], Loss: 1.5479\n",
      "Epoch [17/150], Step [20/168], Loss: 0.9200\n",
      "Epoch [17/150], Step [30/168], Loss: 0.7812\n",
      "Epoch [17/150], Step [40/168], Loss: 0.7512\n",
      "Epoch [17/150], Step [50/168], Loss: 0.6417\n",
      "Epoch [17/150], Step [60/168], Loss: 0.7872\n",
      "Epoch [17/150], Step [70/168], Loss: 0.6777\n",
      "Epoch [17/150], Step [80/168], Loss: 0.5418\n",
      "Epoch [17/150], Step [90/168], Loss: 0.5023\n",
      "Epoch [17/150], Step [100/168], Loss: 0.7816\n",
      "Epoch [17/150], Step [110/168], Loss: 0.6588\n",
      "Epoch [17/150], Step [120/168], Loss: 0.6176\n",
      "Epoch [17/150], Step [130/168], Loss: 2.3335\n",
      "Epoch [17/150], Step [140/168], Loss: 1.8686\n",
      "Epoch [17/150], Step [150/168], Loss: 1.8848\n",
      "Epoch [17/150], Step [160/168], Loss: 1.7987\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [18/150], Step [10/168], Loss: 1.0723\n",
      "Epoch [18/150], Step [20/168], Loss: 0.9740\n",
      "Epoch [18/150], Step [30/168], Loss: 0.8674\n",
      "Epoch [18/150], Step [40/168], Loss: 0.8456\n",
      "Epoch [18/150], Step [50/168], Loss: 0.7893\n",
      "Epoch [18/150], Step [60/168], Loss: 0.8322\n",
      "Epoch [18/150], Step [70/168], Loss: 0.7535\n",
      "Epoch [18/150], Step [80/168], Loss: 0.6329\n",
      "Epoch [18/150], Step [90/168], Loss: 0.5992\n",
      "Epoch [18/150], Step [100/168], Loss: 0.8294\n",
      "Epoch [18/150], Step [110/168], Loss: 0.6612\n",
      "Epoch [18/150], Step [120/168], Loss: 0.6230\n",
      "Epoch [18/150], Step [130/168], Loss: 2.2505\n",
      "Epoch [18/150], Step [140/168], Loss: 1.7052\n",
      "Epoch [18/150], Step [150/168], Loss: 1.2265\n",
      "Epoch [18/150], Step [160/168], Loss: 1.2944\n",
      "Epoch [19/150], Step [10/168], Loss: 0.7558\n",
      "Epoch [19/150], Step [20/168], Loss: 0.8298\n",
      "Epoch [19/150], Step [30/168], Loss: 0.5779\n",
      "Epoch [19/150], Step [40/168], Loss: 0.7202\n",
      "Epoch [19/150], Step [50/168], Loss: 0.6156\n",
      "Epoch [19/150], Step [60/168], Loss: 0.7863\n",
      "Epoch [19/150], Step [70/168], Loss: 0.6491\n",
      "Epoch [19/150], Step [80/168], Loss: 0.5324\n",
      "Epoch [19/150], Step [90/168], Loss: 0.4983\n",
      "Epoch [19/150], Step [100/168], Loss: 0.8203\n",
      "Epoch [19/150], Step [110/168], Loss: 0.6677\n",
      "Epoch [19/150], Step [120/168], Loss: 0.6337\n",
      "Epoch [19/150], Step [130/168], Loss: 2.2424\n",
      "Epoch [19/150], Step [140/168], Loss: 1.7528\n",
      "Epoch [19/150], Step [150/168], Loss: 1.3855\n",
      "Epoch [19/150], Step [160/168], Loss: 1.2764\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [20/150], Step [10/168], Loss: 1.8103\n",
      "Epoch [20/150], Step [20/168], Loss: 0.8474\n",
      "Epoch [20/150], Step [30/168], Loss: 0.5893\n",
      "Epoch [20/150], Step [40/168], Loss: 0.7339\n",
      "Epoch [20/150], Step [50/168], Loss: 0.6469\n",
      "Epoch [20/150], Step [60/168], Loss: 0.7740\n",
      "Epoch [20/150], Step [70/168], Loss: 0.6514\n",
      "Epoch [20/150], Step [80/168], Loss: 0.5527\n",
      "Epoch [20/150], Step [90/168], Loss: 0.5068\n",
      "Epoch [20/150], Step [100/168], Loss: 0.7984\n",
      "Epoch [20/150], Step [110/168], Loss: 0.6596\n",
      "Epoch [20/150], Step [120/168], Loss: 0.6367\n",
      "Epoch [20/150], Step [130/168], Loss: 2.3807\n",
      "Epoch [20/150], Step [140/168], Loss: 1.9056\n",
      "Epoch [20/150], Step [150/168], Loss: 1.7990\n",
      "Epoch [20/150], Step [160/168], Loss: 1.3416\n",
      "Epoch [21/150], Step [10/168], Loss: 0.8358\n",
      "Epoch [21/150], Step [20/168], Loss: 0.8812\n",
      "Epoch [21/150], Step [30/168], Loss: 0.6370\n",
      "Epoch [21/150], Step [40/168], Loss: 0.7397\n",
      "Epoch [21/150], Step [50/168], Loss: 0.6366\n",
      "Epoch [21/150], Step [60/168], Loss: 0.7802\n",
      "Epoch [21/150], Step [70/168], Loss: 0.6600\n",
      "Epoch [21/150], Step [80/168], Loss: 0.5450\n",
      "Epoch [21/150], Step [90/168], Loss: 0.4945\n",
      "Epoch [21/150], Step [100/168], Loss: 0.7817\n",
      "Epoch [21/150], Step [110/168], Loss: 0.6710\n",
      "Epoch [21/150], Step [120/168], Loss: 0.6152\n",
      "Epoch [21/150], Step [130/168], Loss: 2.2794\n",
      "Epoch [21/150], Step [140/168], Loss: 1.5676\n",
      "Epoch [21/150], Step [150/168], Loss: 1.2169\n",
      "Epoch [21/150], Step [160/168], Loss: 1.2687\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [22/150], Step [10/168], Loss: 2.1651\n",
      "Epoch [22/150], Step [20/168], Loss: 0.9381\n",
      "Epoch [22/150], Step [30/168], Loss: 0.5560\n",
      "Epoch [22/150], Step [40/168], Loss: 0.7284\n",
      "Epoch [22/150], Step [50/168], Loss: 0.6296\n",
      "Epoch [22/150], Step [60/168], Loss: 0.7938\n",
      "Epoch [22/150], Step [70/168], Loss: 0.6567\n",
      "Epoch [22/150], Step [80/168], Loss: 0.5604\n",
      "Epoch [22/150], Step [90/168], Loss: 0.5360\n",
      "Epoch [22/150], Step [100/168], Loss: 0.7800\n",
      "Epoch [22/150], Step [110/168], Loss: 0.6803\n",
      "Epoch [22/150], Step [120/168], Loss: 0.6340\n",
      "Epoch [22/150], Step [130/168], Loss: 2.3194\n",
      "Epoch [22/150], Step [140/168], Loss: 1.7488\n",
      "Epoch [22/150], Step [150/168], Loss: 1.7432\n",
      "Epoch [22/150], Step [160/168], Loss: 1.6046\n",
      "Epoch [23/150], Step [10/168], Loss: 1.4618\n",
      "Epoch [23/150], Step [20/168], Loss: 0.9582\n",
      "Epoch [23/150], Step [30/168], Loss: 0.6017\n",
      "Epoch [23/150], Step [40/168], Loss: 0.7813\n",
      "Epoch [23/150], Step [50/168], Loss: 0.6757\n",
      "Epoch [23/150], Step [60/168], Loss: 0.7793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/150], Step [70/168], Loss: 0.6527\n",
      "Epoch [23/150], Step [80/168], Loss: 0.5626\n",
      "Epoch [23/150], Step [90/168], Loss: 0.4990\n",
      "Epoch [23/150], Step [100/168], Loss: 0.7704\n",
      "Epoch [23/150], Step [110/168], Loss: 0.6596\n",
      "Epoch [23/150], Step [120/168], Loss: 0.6293\n",
      "Epoch [23/150], Step [130/168], Loss: 2.3106\n",
      "Epoch [23/150], Step [140/168], Loss: 1.6323\n",
      "Epoch [23/150], Step [150/168], Loss: 1.3059\n",
      "Epoch [23/150], Step [160/168], Loss: 1.2493\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [24/150], Step [10/168], Loss: 1.5933\n",
      "Epoch [24/150], Step [20/168], Loss: 0.8830\n",
      "Epoch [24/150], Step [30/168], Loss: 0.5718\n",
      "Epoch [24/150], Step [40/168], Loss: 0.7278\n",
      "Epoch [24/150], Step [50/168], Loss: 0.6224\n",
      "Epoch [24/150], Step [60/168], Loss: 0.8100\n",
      "Epoch [24/150], Step [70/168], Loss: 0.7037\n",
      "Epoch [24/150], Step [80/168], Loss: 0.5480\n",
      "Epoch [24/150], Step [90/168], Loss: 0.4894\n",
      "Epoch [24/150], Step [100/168], Loss: 0.7779\n",
      "Epoch [24/150], Step [110/168], Loss: 0.6511\n",
      "Epoch [24/150], Step [120/168], Loss: 0.6181\n",
      "Epoch [24/150], Step [130/168], Loss: 2.2684\n",
      "Epoch [24/150], Step [140/168], Loss: 1.1874\n",
      "Epoch [24/150], Step [150/168], Loss: 1.1825\n",
      "Epoch [24/150], Step [160/168], Loss: 1.2532\n",
      "Epoch [25/150], Step [10/168], Loss: 0.8810\n",
      "Epoch [25/150], Step [20/168], Loss: 0.9165\n",
      "Epoch [25/150], Step [30/168], Loss: 0.6317\n",
      "Epoch [25/150], Step [40/168], Loss: 0.7374\n",
      "Epoch [25/150], Step [50/168], Loss: 0.6307\n",
      "Epoch [25/150], Step [60/168], Loss: 0.7788\n",
      "Epoch [25/150], Step [70/168], Loss: 0.6521\n",
      "Epoch [25/150], Step [80/168], Loss: 0.5477\n",
      "Epoch [25/150], Step [90/168], Loss: 0.4940\n",
      "Epoch [25/150], Step [100/168], Loss: 0.7605\n",
      "Epoch [25/150], Step [110/168], Loss: 0.6750\n",
      "Epoch [25/150], Step [120/168], Loss: 0.6156\n",
      "Epoch [25/150], Step [130/168], Loss: 2.2967\n",
      "Epoch [25/150], Step [140/168], Loss: 1.6579\n",
      "Epoch [25/150], Step [150/168], Loss: 1.5880\n",
      "Epoch [25/150], Step [160/168], Loss: 1.3063\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [26/150], Step [10/168], Loss: 2.2404\n",
      "Epoch [26/150], Step [20/168], Loss: 0.9212\n",
      "Epoch [26/150], Step [30/168], Loss: 0.6360\n",
      "Epoch [26/150], Step [40/168], Loss: 0.7409\n",
      "Epoch [26/150], Step [50/168], Loss: 0.6346\n",
      "Epoch [26/150], Step [60/168], Loss: 0.7980\n",
      "Epoch [26/150], Step [70/168], Loss: 0.6692\n",
      "Epoch [26/150], Step [80/168], Loss: 0.5568\n",
      "Epoch [26/150], Step [90/168], Loss: 0.5295\n",
      "Epoch [26/150], Step [100/168], Loss: 0.7799\n",
      "Epoch [26/150], Step [110/168], Loss: 0.6532\n",
      "Epoch [26/150], Step [120/168], Loss: 0.6237\n",
      "Epoch [26/150], Step [130/168], Loss: 2.2737\n",
      "Epoch [26/150], Step [140/168], Loss: 1.0909\n",
      "Epoch [26/150], Step [150/168], Loss: 1.1694\n",
      "Epoch [26/150], Step [160/168], Loss: 1.2083\n",
      "Epoch [27/150], Step [10/168], Loss: 0.8630\n",
      "Epoch [27/150], Step [20/168], Loss: 0.9271\n",
      "Epoch [27/150], Step [30/168], Loss: 0.6267\n",
      "Epoch [27/150], Step [40/168], Loss: 0.7271\n",
      "Epoch [27/150], Step [50/168], Loss: 0.6456\n",
      "Epoch [27/150], Step [60/168], Loss: 0.7750\n",
      "Epoch [27/150], Step [70/168], Loss: 0.6686\n",
      "Epoch [27/150], Step [80/168], Loss: 0.5586\n",
      "Epoch [27/150], Step [90/168], Loss: 0.4975\n",
      "Epoch [27/150], Step [100/168], Loss: 0.7878\n",
      "Epoch [27/150], Step [110/168], Loss: 0.6580\n",
      "Epoch [27/150], Step [120/168], Loss: 0.6156\n",
      "Epoch [27/150], Step [130/168], Loss: 2.3401\n",
      "Epoch [27/150], Step [140/168], Loss: 1.2365\n",
      "Epoch [27/150], Step [150/168], Loss: 1.1729\n",
      "Epoch [27/150], Step [160/168], Loss: 1.2903\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [28/150], Step [10/168], Loss: 0.9257\n",
      "Epoch [28/150], Step [20/168], Loss: 0.8413\n",
      "Epoch [28/150], Step [30/168], Loss: 0.6054\n",
      "Epoch [28/150], Step [40/168], Loss: 0.7386\n",
      "Epoch [28/150], Step [50/168], Loss: 0.6562\n",
      "Epoch [28/150], Step [60/168], Loss: 0.7645\n",
      "Epoch [28/150], Step [70/168], Loss: 0.6683\n",
      "Epoch [28/150], Step [80/168], Loss: 0.5657\n",
      "Epoch [28/150], Step [90/168], Loss: 0.5030\n",
      "Epoch [28/150], Step [100/168], Loss: 0.7857\n",
      "Epoch [28/150], Step [110/168], Loss: 0.6525\n",
      "Epoch [28/150], Step [120/168], Loss: 0.6219\n",
      "Epoch [28/150], Step [130/168], Loss: 2.2636\n",
      "Epoch [28/150], Step [140/168], Loss: 1.6740\n",
      "Epoch [28/150], Step [150/168], Loss: 1.3223\n",
      "Epoch [28/150], Step [160/168], Loss: 1.2502\n",
      "Epoch [29/150], Step [10/168], Loss: 1.3661\n",
      "Epoch [29/150], Step [20/168], Loss: 0.8640\n",
      "Epoch [29/150], Step [30/168], Loss: 0.5740\n",
      "Epoch [29/150], Step [40/168], Loss: 0.7266\n",
      "Epoch [29/150], Step [50/168], Loss: 0.6427\n",
      "Epoch [29/150], Step [60/168], Loss: 0.7776\n",
      "Epoch [29/150], Step [70/168], Loss: 0.6805\n",
      "Epoch [29/150], Step [80/168], Loss: 0.5452\n",
      "Epoch [29/150], Step [90/168], Loss: 0.5054\n",
      "Epoch [29/150], Step [100/168], Loss: 0.8112\n",
      "Epoch [29/150], Step [110/168], Loss: 0.6561\n",
      "Epoch [29/150], Step [120/168], Loss: 0.6197\n",
      "Epoch [29/150], Step [130/168], Loss: 2.2494\n",
      "Epoch [29/150], Step [140/168], Loss: 1.6495\n",
      "Epoch [29/150], Step [150/168], Loss: 1.5647\n",
      "Epoch [29/150], Step [160/168], Loss: 1.3480\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [30/150], Step [10/168], Loss: 1.7269\n",
      "Epoch [30/150], Step [20/168], Loss: 0.9142\n",
      "Epoch [30/150], Step [30/168], Loss: 0.5983\n",
      "Epoch [30/150], Step [40/168], Loss: 0.7188\n",
      "Epoch [30/150], Step [50/168], Loss: 0.6511\n",
      "Epoch [30/150], Step [60/168], Loss: 0.7609\n",
      "Epoch [30/150], Step [70/168], Loss: 0.6665\n",
      "Epoch [30/150], Step [80/168], Loss: 0.5522\n",
      "Epoch [30/150], Step [90/168], Loss: 0.5038\n",
      "Epoch [30/150], Step [100/168], Loss: 0.7804\n",
      "Epoch [30/150], Step [110/168], Loss: 0.6532\n",
      "Epoch [30/150], Step [120/168], Loss: 0.6252\n",
      "Epoch [30/150], Step [130/168], Loss: 2.2696\n",
      "Epoch [30/150], Step [140/168], Loss: 1.6198\n",
      "Epoch [30/150], Step [150/168], Loss: 1.4418\n",
      "Epoch [30/150], Step [160/168], Loss: 1.2822\n",
      "Epoch [31/150], Step [10/168], Loss: 2.1747\n",
      "Epoch [31/150], Step [20/168], Loss: 0.9660\n",
      "Epoch [31/150], Step [30/168], Loss: 0.6200\n",
      "Epoch [31/150], Step [40/168], Loss: 0.7442\n",
      "Epoch [31/150], Step [50/168], Loss: 0.6311\n",
      "Epoch [31/150], Step [60/168], Loss: 0.7683\n",
      "Epoch [31/150], Step [70/168], Loss: 0.6819\n",
      "Epoch [31/150], Step [80/168], Loss: 0.5494\n",
      "Epoch [31/150], Step [90/168], Loss: 0.5056\n",
      "Epoch [31/150], Step [100/168], Loss: 0.8120\n",
      "Epoch [31/150], Step [110/168], Loss: 0.6594\n",
      "Epoch [31/150], Step [120/168], Loss: 0.6231\n",
      "Epoch [31/150], Step [130/168], Loss: 2.3088\n",
      "Epoch [31/150], Step [140/168], Loss: 1.5560\n",
      "Epoch [31/150], Step [150/168], Loss: 1.5092\n",
      "Epoch [31/150], Step [160/168], Loss: 1.2706\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [32/150], Step [10/168], Loss: 1.6168\n",
      "Epoch [32/150], Step [20/168], Loss: 0.9799\n",
      "Epoch [32/150], Step [30/168], Loss: 0.6300\n",
      "Epoch [32/150], Step [40/168], Loss: 0.7625\n",
      "Epoch [32/150], Step [50/168], Loss: 0.6556\n",
      "Epoch [32/150], Step [60/168], Loss: 0.7784\n",
      "Epoch [32/150], Step [70/168], Loss: 0.6619\n",
      "Epoch [32/150], Step [80/168], Loss: 0.5334\n",
      "Epoch [32/150], Step [90/168], Loss: 0.5030\n",
      "Epoch [32/150], Step [100/168], Loss: 0.7674\n",
      "Epoch [32/150], Step [110/168], Loss: 0.6611\n",
      "Epoch [32/150], Step [120/168], Loss: 0.6321\n",
      "Epoch [32/150], Step [130/168], Loss: 2.2698\n",
      "Epoch [32/150], Step [140/168], Loss: 1.6432\n",
      "Epoch [32/150], Step [150/168], Loss: 1.6046\n",
      "Epoch [32/150], Step [160/168], Loss: 1.4612\n",
      "Epoch [33/150], Step [10/168], Loss: 1.5049\n",
      "Epoch [33/150], Step [20/168], Loss: 0.9444\n",
      "Epoch [33/150], Step [30/168], Loss: 0.6220\n",
      "Epoch [33/150], Step [40/168], Loss: 0.7465\n",
      "Epoch [33/150], Step [50/168], Loss: 0.6642\n",
      "Epoch [33/150], Step [60/168], Loss: 0.7724\n",
      "Epoch [33/150], Step [70/168], Loss: 0.6712\n",
      "Epoch [33/150], Step [80/168], Loss: 0.5275\n",
      "Epoch [33/150], Step [90/168], Loss: 0.4990\n",
      "Epoch [33/150], Step [100/168], Loss: 0.7820\n",
      "Epoch [33/150], Step [110/168], Loss: 0.6554\n",
      "Epoch [33/150], Step [120/168], Loss: 0.6109\n",
      "Epoch [33/150], Step [130/168], Loss: 2.2518\n",
      "Epoch [33/150], Step [140/168], Loss: 1.5336\n",
      "Epoch [33/150], Step [150/168], Loss: 1.5458\n",
      "Epoch [33/150], Step [160/168], Loss: 1.4045\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [34/150], Step [10/168], Loss: 1.3804\n",
      "Epoch [34/150], Step [20/168], Loss: 1.0593\n",
      "Epoch [34/150], Step [30/168], Loss: 0.8371\n",
      "Epoch [34/150], Step [40/168], Loss: 0.7641\n",
      "Epoch [34/150], Step [50/168], Loss: 0.6884\n",
      "Epoch [34/150], Step [60/168], Loss: 0.7870\n",
      "Epoch [34/150], Step [70/168], Loss: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/150], Step [80/168], Loss: 0.5223\n",
      "Epoch [34/150], Step [90/168], Loss: 0.5048\n",
      "Epoch [34/150], Step [100/168], Loss: 0.7763\n",
      "Epoch [34/150], Step [110/168], Loss: 0.6589\n",
      "Epoch [34/150], Step [120/168], Loss: 0.6229\n",
      "Epoch [34/150], Step [130/168], Loss: 2.2687\n",
      "Epoch [34/150], Step [140/168], Loss: 1.5409\n",
      "Epoch [34/150], Step [150/168], Loss: 1.3226\n",
      "Epoch [34/150], Step [160/168], Loss: 1.2656\n",
      "Epoch [35/150], Step [10/168], Loss: 2.2739\n",
      "Epoch [35/150], Step [20/168], Loss: 0.9697\n",
      "Epoch [35/150], Step [30/168], Loss: 0.5903\n",
      "Epoch [35/150], Step [40/168], Loss: 0.7141\n",
      "Epoch [35/150], Step [50/168], Loss: 0.6374\n",
      "Epoch [35/150], Step [60/168], Loss: 0.7821\n",
      "Epoch [35/150], Step [70/168], Loss: 0.6768\n",
      "Epoch [35/150], Step [80/168], Loss: 0.5393\n",
      "Epoch [35/150], Step [90/168], Loss: 0.5175\n",
      "Epoch [35/150], Step [100/168], Loss: 0.7712\n",
      "Epoch [35/150], Step [110/168], Loss: 0.6673\n",
      "Epoch [35/150], Step [120/168], Loss: 0.6204\n",
      "Epoch [35/150], Step [130/168], Loss: 2.2396\n",
      "Epoch [35/150], Step [140/168], Loss: 1.7940\n",
      "Epoch [35/150], Step [150/168], Loss: 1.7891\n",
      "Epoch [35/150], Step [160/168], Loss: 1.6892\n",
      " Lr: 0.01 , Validataion accuracy is: 56.073138876795824 %\n",
      "Epoch [36/150], Step [10/168], Loss: 1.1652\n",
      "Epoch [36/150], Step [20/168], Loss: 1.0823\n",
      "Epoch [36/150], Step [30/168], Loss: 0.8925\n",
      "Epoch [36/150], Step [40/168], Loss: 0.7701\n",
      "Epoch [36/150], Step [50/168], Loss: 0.6707\n",
      "Epoch [36/150], Step [60/168], Loss: 0.7768\n",
      "Epoch [36/150], Step [70/168], Loss: 0.6703\n",
      "Epoch [36/150], Step [80/168], Loss: 0.5635\n",
      "Epoch [36/150], Step [90/168], Loss: 0.4982\n",
      "Epoch [36/150], Step [100/168], Loss: 0.7703\n",
      "Epoch [36/150], Step [110/168], Loss: 0.6645\n",
      "Epoch [36/150], Step [120/168], Loss: 0.6169\n",
      "Epoch [36/150], Step [130/168], Loss: 2.2844\n",
      "Epoch [36/150], Step [140/168], Loss: 1.6530\n",
      "Epoch [36/150], Step [150/168], Loss: 1.6704\n",
      "Epoch [36/150], Step [160/168], Loss: 1.6434\n",
      "Epoch [37/150], Step [10/168], Loss: 1.2374\n",
      "Epoch [37/150], Step [20/168], Loss: 1.1321\n",
      "Epoch [37/150], Step [30/168], Loss: 1.0359\n",
      "Epoch [37/150], Step [40/168], Loss: 1.0090\n",
      "Epoch [37/150], Step [50/168], Loss: 0.8045\n",
      "Epoch [37/150], Step [60/168], Loss: 0.8840\n",
      "Epoch [37/150], Step [70/168], Loss: 0.7467\n",
      "Epoch [37/150], Step [80/168], Loss: 0.6539\n",
      "Epoch [37/150], Step [90/168], Loss: 0.6456\n",
      "Epoch [37/150], Step [100/168], Loss: 0.7905\n",
      "Epoch [37/150], Step [110/168], Loss: 0.7092\n",
      "Epoch [37/150], Step [120/168], Loss: 0.6657\n",
      "Epoch [37/150], Step [130/168], Loss: 2.2279\n",
      "Epoch [37/150], Step [140/168], Loss: 2.1097\n",
      "Epoch [37/150], Step [150/168], Loss: 2.0309\n",
      "Epoch [37/150], Step [160/168], Loss: 1.9167\n",
      " Lr: 0.01 , Validataion accuracy is: 3.0256856769699607 %\n",
      "Epoch [38/150], Step [10/168], Loss: 0.9911\n",
      "Epoch [38/150], Step [20/168], Loss: 0.9944\n",
      "Epoch [38/150], Step [30/168], Loss: 0.9055\n",
      "Epoch [38/150], Step [40/168], Loss: 0.8824\n",
      "Epoch [38/150], Step [50/168], Loss: 0.7637\n",
      "Epoch [38/150], Step [60/168], Loss: 0.8479\n",
      "Epoch [38/150], Step [70/168], Loss: 0.7194\n",
      "Epoch [38/150], Step [80/168], Loss: 0.6291\n",
      "Epoch [38/150], Step [90/168], Loss: 0.6222\n",
      "Epoch [38/150], Step [100/168], Loss: 0.7834\n",
      "Epoch [38/150], Step [110/168], Loss: 0.6932\n",
      "Epoch [38/150], Step [120/168], Loss: 0.6527\n",
      "Epoch [38/150], Step [130/168], Loss: 2.2654\n",
      "Epoch [38/150], Step [140/168], Loss: 2.1473\n",
      "Epoch [38/150], Step [150/168], Loss: 2.0663\n",
      "Epoch [38/150], Step [160/168], Loss: 1.8821\n",
      "Epoch [39/150], Step [10/168], Loss: 0.9384\n",
      "Epoch [39/150], Step [20/168], Loss: 0.9646\n",
      "Epoch [39/150], Step [30/168], Loss: 0.8612\n",
      "Epoch [39/150], Step [40/168], Loss: 0.8687\n",
      "Epoch [39/150], Step [50/168], Loss: 0.7335\n",
      "Epoch [39/150], Step [60/168], Loss: 0.8586\n",
      "Epoch [39/150], Step [70/168], Loss: 0.7045\n",
      "Epoch [39/150], Step [80/168], Loss: 0.6162\n",
      "Epoch [39/150], Step [90/168], Loss: 0.6271\n",
      "Epoch [39/150], Step [100/168], Loss: 0.7805\n",
      "Epoch [39/150], Step [110/168], Loss: 0.6896\n",
      "Epoch [39/150], Step [120/168], Loss: 0.6592\n",
      "Epoch [39/150], Step [130/168], Loss: 2.2489\n",
      "Epoch [39/150], Step [140/168], Loss: 2.1225\n",
      "Epoch [39/150], Step [150/168], Loss: 1.6941\n",
      "Epoch [39/150], Step [160/168], Loss: 1.2676\n",
      " Lr: 0.01 , Validataion accuracy is: 56.18197649107532 %\n",
      "Epoch [40/150], Step [10/168], Loss: 2.0806\n",
      "Epoch [40/150], Step [20/168], Loss: 0.8683\n",
      "Epoch [40/150], Step [30/168], Loss: 0.6883\n",
      "Epoch [40/150], Step [40/168], Loss: 0.7859\n",
      "Epoch [40/150], Step [50/168], Loss: 0.6718\n",
      "Epoch [40/150], Step [60/168], Loss: 0.7852\n",
      "Epoch [40/150], Step [70/168], Loss: 0.6656\n",
      "Epoch [40/150], Step [80/168], Loss: 0.5679\n",
      "Epoch [40/150], Step [90/168], Loss: 0.5752\n",
      "Epoch [40/150], Step [100/168], Loss: 0.7673\n",
      "Epoch [40/150], Step [110/168], Loss: 0.6695\n",
      "Epoch [40/150], Step [120/168], Loss: 0.6327\n",
      "Epoch [40/150], Step [130/168], Loss: 2.3632\n",
      "Epoch [40/150], Step [140/168], Loss: 2.2263\n",
      "Epoch [40/150], Step [150/168], Loss: 2.1277\n",
      "Epoch [40/150], Step [160/168], Loss: 1.9556\n",
      "Epoch [41/150], Step [10/168], Loss: 0.9196\n",
      "Epoch [41/150], Step [20/168], Loss: 0.9304\n",
      "Epoch [41/150], Step [30/168], Loss: 0.8095\n",
      "Epoch [41/150], Step [40/168], Loss: 0.8861\n",
      "Epoch [41/150], Step [50/168], Loss: 0.6799\n",
      "Epoch [41/150], Step [60/168], Loss: 0.8473\n",
      "Epoch [41/150], Step [70/168], Loss: 0.6822\n",
      "Epoch [41/150], Step [80/168], Loss: 0.5874\n",
      "Epoch [41/150], Step [90/168], Loss: 0.5956\n",
      "Epoch [41/150], Step [100/168], Loss: 0.7840\n",
      "Epoch [41/150], Step [110/168], Loss: 0.6881\n",
      "Epoch [41/150], Step [120/168], Loss: 0.6615\n",
      "Epoch [41/150], Step [130/168], Loss: 2.2896\n",
      "Epoch [41/150], Step [140/168], Loss: 2.1078\n",
      "Epoch [41/150], Step [150/168], Loss: 2.0353\n",
      "Epoch [41/150], Step [160/168], Loss: 1.8202\n",
      " Lr: 0.01 , Validataion accuracy is: 56.24727905964301 %\n",
      "Epoch [42/150], Step [10/168], Loss: 1.1708\n",
      "Epoch [42/150], Step [20/168], Loss: 0.9267\n",
      "Epoch [42/150], Step [30/168], Loss: 0.7771\n",
      "Epoch [42/150], Step [40/168], Loss: 0.8626\n",
      "Epoch [42/150], Step [50/168], Loss: 0.6809\n",
      "Epoch [42/150], Step [60/168], Loss: 0.8496\n",
      "Epoch [42/150], Step [70/168], Loss: 0.6972\n",
      "Epoch [42/150], Step [80/168], Loss: 0.5887\n",
      "Epoch [42/150], Step [90/168], Loss: 0.5935\n",
      "Epoch [42/150], Step [100/168], Loss: 0.7890\n",
      "Epoch [42/150], Step [110/168], Loss: 0.6913\n",
      "Epoch [42/150], Step [120/168], Loss: 0.6648\n",
      "Epoch [42/150], Step [130/168], Loss: 2.2422\n",
      "Epoch [42/150], Step [140/168], Loss: 2.1229\n",
      "Epoch [42/150], Step [150/168], Loss: 2.0546\n",
      "Epoch [42/150], Step [160/168], Loss: 1.9578\n",
      "Epoch [43/150], Step [10/168], Loss: 0.9362\n",
      "Epoch [43/150], Step [20/168], Loss: 0.9716\n",
      "Epoch [43/150], Step [30/168], Loss: 0.8822\n",
      "Epoch [43/150], Step [40/168], Loss: 0.8721\n",
      "Epoch [43/150], Step [50/168], Loss: 0.7585\n",
      "Epoch [43/150], Step [60/168], Loss: 0.8459\n",
      "Epoch [43/150], Step [70/168], Loss: 0.7192\n",
      "Epoch [43/150], Step [80/168], Loss: 0.6331\n",
      "Epoch [43/150], Step [90/168], Loss: 0.6036\n",
      "Epoch [43/150], Step [100/168], Loss: 0.7845\n",
      "Epoch [43/150], Step [110/168], Loss: 0.6899\n",
      "Epoch [43/150], Step [120/168], Loss: 0.6544\n",
      "Epoch [43/150], Step [130/168], Loss: 2.2722\n",
      "Epoch [43/150], Step [140/168], Loss: 2.1412\n",
      "Epoch [43/150], Step [150/168], Loss: 2.0756\n",
      "Epoch [43/150], Step [160/168], Loss: 1.9822\n",
      " Lr: 0.01 , Validataion accuracy is: 0.391815411406182 %\n",
      "Epoch [44/150], Step [10/168], Loss: 0.9293\n",
      "Epoch [44/150], Step [20/168], Loss: 0.9706\n",
      "Epoch [44/150], Step [30/168], Loss: 0.8865\n",
      "Epoch [44/150], Step [40/168], Loss: 0.8764\n",
      "Epoch [44/150], Step [50/168], Loss: 0.7625\n",
      "Epoch [44/150], Step [60/168], Loss: 0.8498\n",
      "Epoch [44/150], Step [70/168], Loss: 0.7235\n",
      "Epoch [44/150], Step [80/168], Loss: 0.6387\n",
      "Epoch [44/150], Step [90/168], Loss: 0.6071\n",
      "Epoch [44/150], Step [100/168], Loss: 0.7893\n",
      "Epoch [44/150], Step [110/168], Loss: 0.6932\n",
      "Epoch [44/150], Step [120/168], Loss: 0.6604\n",
      "Epoch [44/150], Step [130/168], Loss: 2.2457\n",
      "Epoch [44/150], Step [140/168], Loss: 2.1428\n",
      "Epoch [44/150], Step [150/168], Loss: 2.0776\n",
      "Epoch [44/150], Step [160/168], Loss: 1.9845\n",
      "Epoch [45/150], Step [10/168], Loss: 0.9189\n",
      "Epoch [45/150], Step [20/168], Loss: 0.9653\n",
      "Epoch [45/150], Step [30/168], Loss: 0.8534\n",
      "Epoch [45/150], Step [40/168], Loss: 0.9149\n",
      "Epoch [45/150], Step [50/168], Loss: 0.6958\n",
      "Epoch [45/150], Step [60/168], Loss: 0.8309\n",
      "Epoch [45/150], Step [70/168], Loss: 0.7007\n",
      "Epoch [45/150], Step [80/168], Loss: 0.6116\n",
      "Epoch [45/150], Step [90/168], Loss: 0.6280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/150], Step [100/168], Loss: 0.7845\n",
      "Epoch [45/150], Step [110/168], Loss: 0.6783\n",
      "Epoch [45/150], Step [120/168], Loss: 0.6483\n",
      "Epoch [45/150], Step [130/168], Loss: 2.3050\n",
      "Epoch [45/150], Step [140/168], Loss: 2.0264\n",
      "Epoch [45/150], Step [150/168], Loss: 1.9955\n",
      "Epoch [45/150], Step [160/168], Loss: 1.9224\n",
      " Lr: 0.01 , Validataion accuracy is: 9.599477579451458 %\n",
      "Epoch [46/150], Step [10/168], Loss: 0.9937\n",
      "Epoch [46/150], Step [20/168], Loss: 0.9869\n",
      "Epoch [46/150], Step [30/168], Loss: 0.9035\n",
      "Epoch [46/150], Step [40/168], Loss: 0.8841\n",
      "Epoch [46/150], Step [50/168], Loss: 0.7709\n",
      "Epoch [46/150], Step [60/168], Loss: 0.8539\n",
      "Epoch [46/150], Step [70/168], Loss: 0.7274\n",
      "Epoch [46/150], Step [80/168], Loss: 0.6406\n",
      "Epoch [46/150], Step [90/168], Loss: 0.6116\n",
      "Epoch [46/150], Step [100/168], Loss: 0.7915\n",
      "Epoch [46/150], Step [110/168], Loss: 0.6978\n",
      "Epoch [46/150], Step [120/168], Loss: 0.6610\n",
      "Epoch [46/150], Step [130/168], Loss: 2.2459\n",
      "Epoch [46/150], Step [140/168], Loss: 2.1329\n",
      "Epoch [46/150], Step [150/168], Loss: 2.0821\n",
      "Epoch [46/150], Step [160/168], Loss: 1.9935\n",
      "Epoch [47/150], Step [10/168], Loss: 0.9163\n",
      "Epoch [47/150], Step [20/168], Loss: 0.9695\n",
      "Epoch [47/150], Step [30/168], Loss: 0.8847\n",
      "Epoch [47/150], Step [40/168], Loss: 0.8758\n",
      "Epoch [47/150], Step [50/168], Loss: 0.7648\n",
      "Epoch [47/150], Step [60/168], Loss: 0.8517\n",
      "Epoch [47/150], Step [70/168], Loss: 0.7262\n",
      "Epoch [47/150], Step [80/168], Loss: 0.6418\n",
      "Epoch [47/150], Step [90/168], Loss: 0.6094\n",
      "Epoch [47/150], Step [100/168], Loss: 0.7912\n",
      "Epoch [47/150], Step [110/168], Loss: 0.6952\n",
      "Epoch [47/150], Step [120/168], Loss: 0.6649\n",
      "Epoch [47/150], Step [130/168], Loss: 2.2338\n",
      "Epoch [47/150], Step [140/168], Loss: 2.1390\n",
      "Epoch [47/150], Step [150/168], Loss: 2.0913\n",
      "Epoch [47/150], Step [160/168], Loss: 2.0018\n"
     ]
    }
   ],
   "source": [
    "train_function(k_resnet18, train_loader=k_train_loader, val_loader=k_val_loader, train=True, save_model_path=k_model_path_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d297ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_function(k_resnet18, test_loader=f_full_loader, train=False, save_model_path=k_model_path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72b88fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 276 test images: 61.95652173913044 %\n"
     ]
    }
   ],
   "source": [
    "train_function(k_resnet18, test_loader=val_loader, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7870918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_function(k_resnet18, test_loader=_loader, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
